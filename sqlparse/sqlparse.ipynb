{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_query = '''select a1, count(a2) \n",
    "               from MEOW.AAA_table as t3 \n",
    "                    where t3.X1 = 'thing' and t3.X2 in ('a1', 'a2', 'a3') \n",
    "               Group by a1\n",
    "               limit 15'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'select' at 0x4E32BE8>,\n",
       " <Whitespace ' ' at 0x4E32DC8>,\n",
       " <IdentifierList 'a1, co...' at 0x4E494F8>,\n",
       " <Whitespace ' ' at 0x4D4A108>,\n",
       " <Newline ' ' at 0x4D4A168>,\n",
       " <Whitespace ' ' at 0x4D4A1C8>,\n",
       " <Whitespace ' ' at 0x4D4A228>,\n",
       " <Whitespace ' ' at 0x4D4A288>,\n",
       " <Whitespace ' ' at 0x4D4A2E8>,\n",
       " <Whitespace ' ' at 0x4D4A348>,\n",
       " <Whitespace ' ' at 0x4D4A3A8>,\n",
       " <Whitespace ' ' at 0x4D4A408>,\n",
       " <Whitespace ' ' at 0x4D4A468>,\n",
       " <Whitespace ' ' at 0x4D4A4C8>,\n",
       " <Whitespace ' ' at 0x4D4A528>,\n",
       " <Whitespace ' ' at 0x4D4A588>,\n",
       " <Whitespace ' ' at 0x4D4A5E8>,\n",
       " <Whitespace ' ' at 0x4D4A648>,\n",
       " <Whitespace ' ' at 0x4D4A6A8>,\n",
       " <Whitespace ' ' at 0x4D4A708>,\n",
       " <Keyword 'from' at 0x4D4A768>,\n",
       " <Whitespace ' ' at 0x4D4A7C8>,\n",
       " <Identifier 'MEOW.A...' at 0x4E490C0>,\n",
       " <Whitespace ' ' at 0x4D4AAC8>,\n",
       " <Newline ' ' at 0x4D4AB28>,\n",
       " <Whitespace ' ' at 0x4D4AB88>,\n",
       " <Whitespace ' ' at 0x4D4ABE8>,\n",
       " <Whitespace ' ' at 0x4D4AC48>,\n",
       " <Whitespace ' ' at 0x4D4ACA8>,\n",
       " <Whitespace ' ' at 0x4D4AD08>,\n",
       " <Whitespace ' ' at 0x4D4AD68>,\n",
       " <Whitespace ' ' at 0x4D4ADC8>,\n",
       " <Whitespace ' ' at 0x4D4AE28>,\n",
       " <Whitespace ' ' at 0x4D4AE88>,\n",
       " <Whitespace ' ' at 0x4D4AEE8>,\n",
       " <Whitespace ' ' at 0x4D4AF48>,\n",
       " <Whitespace ' ' at 0x4D4AFA8>,\n",
       " <Whitespace ' ' at 0x4E46048>,\n",
       " <Whitespace ' ' at 0x4E460A8>,\n",
       " <Whitespace ' ' at 0x4E46108>,\n",
       " <Whitespace ' ' at 0x4E46168>,\n",
       " <Whitespace ' ' at 0x4E461C8>,\n",
       " <Whitespace ' ' at 0x4E46228>,\n",
       " <Whitespace ' ' at 0x4E46288>,\n",
       " <Whitespace ' ' at 0x4E462E8>,\n",
       " <Where 'where ...' at 0x4D6BF48>,\n",
       " <Keyword 'Group ...' at 0x4E47408>,\n",
       " <Whitespace ' ' at 0x4E47468>,\n",
       " <Identifier 'a1' at 0x4E49408>,\n",
       " <Newline ' ' at 0x4E47528>,\n",
       " <Whitespace ' ' at 0x4E47588>,\n",
       " <Whitespace ' ' at 0x4E475E8>,\n",
       " <Whitespace ' ' at 0x4E47648>,\n",
       " <Whitespace ' ' at 0x4E476A8>,\n",
       " <Whitespace ' ' at 0x4E47708>,\n",
       " <Whitespace ' ' at 0x4E47768>,\n",
       " <Whitespace ' ' at 0x4E477C8>,\n",
       " <Whitespace ' ' at 0x4E47828>,\n",
       " <Whitespace ' ' at 0x4E47888>,\n",
       " <Whitespace ' ' at 0x4E478E8>,\n",
       " <Whitespace ' ' at 0x4E47948>,\n",
       " <Whitespace ' ' at 0x4E479A8>,\n",
       " <Whitespace ' ' at 0x4E47A08>,\n",
       " <Whitespace ' ' at 0x4E47A68>,\n",
       " <Whitespace ' ' at 0x4E47AC8>,\n",
       " <Keyword 'limit' at 0x4E47B28>,\n",
       " <Whitespace ' ' at 0x4E47B88>,\n",
       " <Integer '15' at 0x4E47BE8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlparse.parse(the_query)\n",
    "stmt = res[0]\n",
    "stmt.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEOW\n",
      "AAA_table\n",
      "t3\n",
      "[<Keyword 'where' at 0x21CCFD1C168>, <Whitespace ' ' at 0x21CCFD1C1C8>, <Comparison 't3.X1 ...' at 0x21CCFE9F148>, <Whitespace ' ' at 0x21CCFD1C768>, <Keyword 'and' at 0x21CCFD1CDC8>, <Whitespace ' ' at 0x21CCFD1C708>, <Identifier 't3.X2' at 0x21CCFE9FAC8>, <Whitespace ' ' at 0x21CCF9D8948>, <Keyword 'in' at 0x21CCF9D8708>, <Whitespace ' ' at 0x21CCF9D8A68>, <Parenthesis '('a1',...' at 0x21CCFF57A48>, <Whitespace ' ' at 0x21CCFB576A8>]\n",
      "t3.X1\n",
      "X1\n",
      "t3.X1 = 'thing'\n"
     ]
    }
   ],
   "source": [
    "print(stmt.tokens[6].get_parent_name())\n",
    "print(stmt.tokens[6].get_real_name())\n",
    "print(stmt.tokens[6].get_name())\n",
    "print(stmt.tokens[8].tokens)\n",
    "print(stmt.tokens[8].tokens[2].token_first())\n",
    "print(stmt.tokens[8].tokens[2].get_name())\n",
    "print(stmt.tokens[8].tokens[2].value)\n",
    "# i = 0\n",
    "# for ii in stmt.tokens[8].tokens:\n",
    "    \n",
    "#     print(i)\n",
    "#     i = i+1\n",
    "#     try:\n",
    "#         if(ii.value == \"where\"):\n",
    "#             continue\n",
    "#         print(ii.value)\n",
    "#         print(ii.get_real_name())\n",
    "#     except Exception as e :\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = stmt.tokens[8].tokens[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X1'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.get_alias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tables = []\n",
    "parsed = sqlparse.parse(the_query)\n",
    "stmt = parsed[0]\n",
    "from_seen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace.Newline\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace.Newline\n",
      "item:===================\n",
      "Token.Text.Whitespace.Newline\n",
      "x:===================\n",
      "Token.Text.Whitespace.Newline\n",
      "x:===================\n",
      "Token.Text.Whitespace.Newline\n",
      "x:===================\n",
      "Token.Text.Whitespace.Newline\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "x:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "x:===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "x:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Punctuation\n",
      "item:===================\n",
      "Token.Punctuation\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "Tables: t1, B, C, D, E, F, G, H, I, J, K\n"
     ]
    }
   ],
   "source": [
    "## 資料表名稱萃取\n",
    "import sqlparse\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML\n",
    "\n",
    "\n",
    "def is_subselect(parsed):\n",
    "    if not parsed.is_group:\n",
    "        return False\n",
    "    for item in parsed.tokens:\n",
    "        if item.ttype is DML and item.value.upper() == 'SELECT':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_from_part(parsed):\n",
    "    from_seen = False\n",
    "    for item in parsed.tokens:\n",
    "        print(\"=======item_FIRST===================\")\n",
    "        print(item.ttype)\n",
    "        if from_seen:\n",
    "            if is_subselect(item):\n",
    "                for x in extract_from_part(item):\n",
    "                    print(\"x:===================\")\n",
    "                    print(x.ttype)\n",
    "                    yield x\n",
    "            elif item.ttype is Keyword:\n",
    "                return\n",
    "            else:\n",
    "                print(\"item:===================\")\n",
    "                print(item.ttype)\n",
    "                yield item\n",
    "        elif item.ttype is Keyword and item.value.upper() == 'FROM':\n",
    "            from_seen = True\n",
    "\n",
    "\n",
    "def extract_table_identifiers(token_stream):\n",
    "    for item in token_stream:\n",
    "        if isinstance(item, IdentifierList):\n",
    "            for identifier in item.get_identifiers():\n",
    "                yield identifier.get_name()\n",
    "        elif isinstance(item, Identifier):\n",
    "            yield item.get_name()\n",
    "        # It's a bug to check for Keyword here, but in the example\n",
    "        # above some tables names are identified as keywords...\n",
    "        elif item.ttype is Keyword:\n",
    "            yield item.value\n",
    "\n",
    "\n",
    "def extract_tables(sql):\n",
    "    stream = extract_from_part(sqlparse.parse(sql)[0])\n",
    "    return list(extract_table_identifiers(stream))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sql = \"\"\"\n",
    "    select K.a,K.b from (select H.b from (select G.c from (select F.d from\n",
    "    (select E.e from MEOW.A as t1 , MEOW.B, MEOW.C, MEOW.D, MEOW.E), F), G), H), I, J, K order by 1,2;\n",
    "    \"\"\"\n",
    "\n",
    "    tables = ', '.join(extract_tables(sql))\n",
    "    print('Tables: {0}'.format(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(stmt.tokens[6].get_parent_name())\n",
    "print(stmt.tokens[6].get_real_name())\n",
    "print(stmt.tokens[6].get_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非槽狀FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_from_part(parsed):\n",
    "    from_seen = False\n",
    "    for item in parsed.tokens:\n",
    "        print(\"=======item_FIRST===================\")\n",
    "        print(item.ttype)\n",
    "        if from_seen:\n",
    "            if is_subselect(item):\n",
    "                for x in extract_from_part(item):\n",
    "                    print(\"x:===================\")\n",
    "                    print(x.ttype)\n",
    "                    yield x\n",
    "            elif item.ttype is Keyword:\n",
    "                return\n",
    "            else:\n",
    "                print(\"item:===================\")\n",
    "                print(item.ttype)\n",
    "                yield item\n",
    "        elif item.ttype is Keyword and item.value.upper() == 'FROM':\n",
    "            from_seen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======item_FIRST===================\n",
      "Token.Keyword.DML\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "Token.Keyword\n",
      "=======item_FIRST===================\n",
      "Token.Text.Whitespace\n",
      "item:===================\n",
      "Token.Text.Whitespace\n",
      "Token.Text.Whitespace\n",
      "=======item_FIRST===================\n",
      "None\n",
      "item:===================\n",
      "None\n",
      "None\n",
      "t1|MEOW|A\n",
      "t2|MEOW|B\n",
      "t3|MEOW|C\n",
      "t4|MEOW|D\n",
      "t5|QUERY|E\n"
     ]
    }
   ],
   "source": [
    "query_tmp = \"select t1.e from MEOW.A as t1 , MEOW.B as t2, MEOW.C as t3, MEOW.D as t4, QUERY.E as t5\"\n",
    "\n",
    "# print(', '.join(extract_tables(query_tmp)))\n",
    "item_part = extract_from_part(sqlparse.parse(query_tmp)[0])\n",
    "\n",
    "for item in item_part :\n",
    "    print(item.ttype)\n",
    "    if isinstance(item, IdentifierList):\n",
    "        for identifier in item.get_identifiers():\n",
    "            print(identifier.get_name() + \"|\"+ identifier.get_parent_name()+ \"|\"+ identifier.get_real_name())\n",
    "#             print(\"===========================\")\n",
    "#             print(identifier.get_name() )\n",
    "#             print(identifier.get_parent_name())\n",
    "#             print(identifier.get_real_name())\n",
    "    elif isinstance(item, Identifier):\n",
    "        print(item.get_name())\n",
    "    # It's a bug to check for Keyword here, but in the example\n",
    "    # above some tables names are identified as keywords...\n",
    "    elif item.ttype is Keyword:\n",
    "        print(item.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHERE \n",
    "https://stackoverflow.com/questions/55398189/parse-sql-select-statement-to-fetch-the-where-clause-conditions-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEOW\n",
      "AAA_table\n",
      "t3\n",
      "[<Keyword 'where' at 0x21CD7150CA8>, <Whitespace ' ' at 0x21CD71DA048>, <Comparison 't3.X1 ...' at 0x21CD72096C8>, <Whitespace ' ' at 0x21CD7210408>, <Keyword 'and' at 0x21CD71759A8>, <Whitespace ' ' at 0x21CD7175588>, <Identifier 't3.X2' at 0x21CD7209248>, <Whitespace ' ' at 0x21CD7175468>, <Keyword 'in' at 0x21CD71755E8>, <Whitespace ' ' at 0x21CD7175828>, <Parenthesis '('a1',...' at 0x21CD72091C8>, <Whitespace ' ' at 0x21CD7218528>]\n",
      "t3.X1\n",
      "X1\n",
      "t3.X1 = 'thing'\n"
     ]
    }
   ],
   "source": [
    "the_query = \"select a1, a2, a3 from MEOW.AAA_table as t3 where t3.X1 = 'thing' and t3.X2 in ('a1', 'a2', 'a3') limit 15\"\n",
    "res = sqlparse.parse(the_query)\n",
    "stmt = res[0]\n",
    "stmt.tokens\n",
    "print(stmt.tokens[6].get_parent_name())\n",
    "print(stmt.tokens[6].get_real_name())\n",
    "print(stmt.tokens[6].get_name())\n",
    "print(stmt.tokens[8].tokens)\n",
    "print(stmt.tokens[8].tokens[2].token_first())\n",
    "print(stmt.tokens[8].tokens[2].get_name())\n",
    "print(stmt.tokens[8].tokens[2].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_first': 't1.employee_type', 'parent': 't1', 'key': 'employee_type', 'value': \"t1.employee_type = 'Employee'\"}\n",
      "{'token_first': 't1.employment_status', 'parent': 't1', 'key': 'employment_status', 'value': \"t1.employment_status = 'Active'\"}\n",
      "{'token_first': 't1.employment_status', 'parent': 't1', 'key': 'employment_status', 'value': \"t1.employment_status = 'On Leave'\"}\n",
      "{'token_first': 't1.time_type', 'parent': 't1', 'key': 'time_type', 'value': \"t1.time_type='Full time'\"}\n",
      "{'token_first': 't1.country_code', 'parent': 't1', 'key': 'country_code', 'value': \"t1.country_code <> 'US'\"}\n",
      "{'token_first': 't1.hire_date', 'parent': 't1', 'key': 'hire_date', 'value': 't1.hire_date < NOW()'}\n",
      "{'token_first': 't1', 'parent': 'NO_PARENT', 'key': 'email_work', 'value': 't1.email_work'}\n",
      "{'token_first': 'LENGTH(t1.email_work)', 'parent': 'LENGTH(t1', 'key': 'LENGTH', 'value': 'LENGTH(t1.email_work) > 0'}\n",
      "{'token_first': 't1', 'parent': 'NO_PARENT', 'key': 'ob_profile_id', 'value': 't1.ob_profile_id'}\n",
      "{'token_first': 'country_code', 'parent': 'NO_PARENT', 'key': 'country_code', 'value': \"country_code = 'IE'\"}\n",
      "{'token_first': 't1', 'parent': 'NO_PARENT', 'key': 'job_profile_id', 'value': 't1.job_profile_id'}\n",
      "{'token_first': 't1', 'parent': 'NO_PARENT', 'key': 'country_code', 'value': 't1.country_code'}\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "import re\n",
    "s = \"select count(*) from users as t1 where t1.employee_type = 'Employee' AND (t1.employment_status = 'Active' OR t1.employment_status = 'On Leave') AND (t1.time_type='Full time' OR t1.country_code <> 'US') AND t1.hire_date < NOW() AND t1.email_work IS NOT NULL AND LENGTH(t1.email_work) > 0 AND NOT (t1.ob_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE') AND t1.job_profile_id NOT IN ('20992', '20993', '20994', '20995', '20996', '20997') AND t1.country_code NOT IN ('CN', 'MO', 'SG', 'MY', 'TH', 'VN', 'MM', 'KH', 'PH', 'ID')\"\n",
    "\n",
    "parsed = sqlparse.parse(s)\n",
    "where = parsed[0][-1]\n",
    "\n",
    "sql_tokens = []\n",
    "def get_tokens(where):\n",
    "    for i in where.tokens:\n",
    "        try:\n",
    "            ### IS NOT 系列處理\n",
    "            \n",
    "            ### () 系列處理\n",
    "            \n",
    "            token_first_list = re.split(\"\\\\.\",str(i.token_first()))\n",
    "            if(len(token_first_list)==1):\n",
    "                parentname = \"NO_PARENT\"\n",
    "            else:\n",
    "                parentname = token_first_list[0]\n",
    "            name = i.get_real_name()\n",
    "            if name and not isinstance(i, sqlparse.sql.Parenthesis):\n",
    "                # sql_tokens.append(\"{0} - {1} - {2}\".format(str(i), str(name), i.value))\n",
    "                sql_tokens.append({\n",
    "                    'token_first':str(i.token_first()),\n",
    "                    'parent':str(parentname),\n",
    "                    'key': str(name),\n",
    "                    'value': i.value,\n",
    "                })\n",
    "            else:\n",
    "                get_tokens(i)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "get_tokens(where)\n",
    "for i in sql_tokens:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1.employee_type'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(where.tokens[2].token_first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where\n",
      " \n",
      "t1.employee_type = 'Employee'\n",
      " \n",
      "AND\n",
      " \n",
      "(t1.employment_status = 'Active' OR t1.employment_status = 'On Leave')\n",
      " \n",
      "AND\n",
      " \n",
      "(t1.time_type='Full time' OR t1.country_code <> 'US')\n",
      " \n",
      "AND\n",
      " \n",
      "t1.hire_date < NOW()\n",
      " \n",
      "AND\n",
      " \n",
      "t1.email_work\n",
      " \n",
      "IS\n",
      " \n",
      "NOT NULL\n",
      " \n",
      "AND\n",
      " \n",
      "LENGTH(t1.email_work) > 0\n",
      " \n",
      "AND\n",
      " \n",
      "NOT\n",
      " \n",
      "(t1.ob_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE')\n",
      " \n",
      "AND\n",
      " \n",
      "t1.job_profile_id\n",
      " \n",
      "NOT\n",
      " \n",
      "IN\n",
      " \n",
      "('20992', '20993', '20994', '20995', '20996', '20997')\n",
      " \n",
      "AND\n",
      " \n",
      "t1.country_code\n",
      " \n",
      "NOT\n",
      " \n",
      "IN\n",
      " \n",
      "('CN', 'MO', 'SG', 'MY', 'TH', 'VN', 'MM', 'KH', 'PH', 'ID')\n"
     ]
    }
   ],
   "source": [
    "for tt in where.tokens:\n",
    "    print (tt.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"where t1.employee_type = 'Employee' AND (t1.employment_status = 'Active' OR t1.employment_status = 'On Leave') AND (t1.time_type='Full time' OR t1.country_code <> 'US') AND t1.hire_date < NOW() AND t1.email_work IS NOT NULL AND LENGTH(t1.email_work) > 0 AND NOT (t1.ob_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE') AND t1.job_profile_id NOT IN ('20992', '20993', '20994', '20995', '20996', '20997') AND t1.country_code NOT IN ('CN', 'MO', 'SG', 'MY', 'TH', 'VN', 'MM', 'KH', 'PH', 'ID')\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Keyword 'where' at 0x21CD6F79BE8>,\n",
       " <Whitespace ' ' at 0x21CD6F79AC8>,\n",
       " <Comparison 't1.emp...' at 0x21CD6F9A148>,\n",
       " <Whitespace ' ' at 0x21CD6F79A68>,\n",
       " <Keyword 'AND' at 0x21CD6F79A08>,\n",
       " <Whitespace ' ' at 0x21CD6F799A8>,\n",
       " <Parenthesis '(t1.em...' at 0x21CD721D6C8>,\n",
       " <Whitespace ' ' at 0x21CD6FFC5E8>,\n",
       " <Keyword 'AND' at 0x21CD6FFC4C8>,\n",
       " <Whitespace ' ' at 0x21CD6FFC0A8>,\n",
       " <Parenthesis '(t1.ti...' at 0x21CD721D348>,\n",
       " <Whitespace ' ' at 0x21CCFB688E8>,\n",
       " <Keyword 'AND' at 0x21CCFB68CA8>,\n",
       " <Whitespace ' ' at 0x21CCFB68B28>,\n",
       " <Comparison 't1.hir...' at 0x21CD6F9A648>,\n",
       " <Whitespace ' ' at 0x21CD7210048>,\n",
       " <Keyword 'AND' at 0x21CD7210B88>,\n",
       " <Whitespace ' ' at 0x21CD72106A8>,\n",
       " <Identifier 't1.ema...' at 0x21CD6F9AE48>,\n",
       " <Whitespace ' ' at 0x21CD7210E88>,\n",
       " <Keyword 'IS' at 0x21CD7210768>,\n",
       " <Whitespace ' ' at 0x21CD72109A8>,\n",
       " <Keyword 'NOT NU...' at 0x21CD7210648>,\n",
       " <Whitespace ' ' at 0x21CD7210EE8>,\n",
       " <Keyword 'AND' at 0x21CD70D4468>,\n",
       " <Whitespace ' ' at 0x21CD70D41C8>,\n",
       " <Comparison 'LENGTH...' at 0x21CD6F9A348>,\n",
       " <Whitespace ' ' at 0x21CD71FCEE8>,\n",
       " <Keyword 'AND' at 0x21CD71FC648>,\n",
       " <Whitespace ' ' at 0x21CD71FC948>,\n",
       " <Keyword 'NOT' at 0x21CD71FCB28>,\n",
       " <Whitespace ' ' at 0x21CD71FC408>,\n",
       " <Parenthesis '(t1.ob...' at 0x21CD721D448>,\n",
       " <Whitespace ' ' at 0x21CD7153048>,\n",
       " <Keyword 'AND' at 0x21CD7153C48>,\n",
       " <Whitespace ' ' at 0x21CD7150FA8>,\n",
       " <Identifier 't1.job...' at 0x21CD6F9A7C8>,\n",
       " <Whitespace ' ' at 0x21CD7150D08>,\n",
       " <Keyword 'NOT' at 0x21CD7150BE8>,\n",
       " <Whitespace ' ' at 0x21CD7150D68>,\n",
       " <Keyword 'IN' at 0x21CD7150B88>,\n",
       " <Whitespace ' ' at 0x21CD7150EE8>,\n",
       " <Parenthesis '('2099...' at 0x21CD721D3C8>,\n",
       " <Whitespace ' ' at 0x21CD7154FA8>,\n",
       " <Keyword 'AND' at 0x21CD71544C8>,\n",
       " <Whitespace ' ' at 0x21CD7154E88>,\n",
       " <Identifier 't1.cou...' at 0x21CD6F9A6C8>,\n",
       " <Whitespace ' ' at 0x21CD7154A68>,\n",
       " <Keyword 'NOT' at 0x21CD7154948>,\n",
       " <Whitespace ' ' at 0x21CD6F84048>,\n",
       " <Keyword 'IN' at 0x21CD6F84D68>,\n",
       " <Whitespace ' ' at 0x21CD6F84108>,\n",
       " <Parenthesis '('CN',...' at 0x21CD721D148>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改寫變得更結構化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "import re\n",
    "s = \"select count(*) from users as t1 where t1.employee_type = 'Employee' AND (t1.employment_status = 'Active' OR t1.employment_status = 'On Leave') AND (t1.time_type='Full time' OR t1.country_code <> 'US') AND t1.hire_date < NOW() AND t1.email_work IS NOT NULL AND LENGTH(t1.email_work) > 0 AND NOT (t1.ob_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE') AND t1.job_profile_id NOT IN ('20992', '20993', '20994', '20995', '20996', '20997') AND t1.country_code NOT IN ('CN', 'MO', 'SG', 'MY', 'TH', 'VN', 'MM', 'KH', 'PH', 'ID')\"\n",
    "\n",
    "parsed = sqlparse.parse(s)\n",
    "where = parsed[0][-1]\n",
    "\n",
    "sql_tokens = []\n",
    "def get_tokens(where):\n",
    "    for i in where.tokens:\n",
    "        try:\n",
    "            token_first_list = re.split(\"\\\\.\",str(i.token_first()))\n",
    "            if(len(token_first_list)==1):\n",
    "                parentname = \"NO_PARENT\"\n",
    "            else:\n",
    "                parentname = token_first_list[0]\n",
    "            name = i.get_real_name()\n",
    "            if name and not isinstance(i, sqlparse.sql.Parenthesis):\n",
    "                # sql_tokens.append(\"{0} - {1} - {2}\".format(str(i), str(name), i.value))\n",
    "                sql_tokens.append({\n",
    "                    'parent':str(parentname),\n",
    "                    'key': str(name),\n",
    "                    'value': i.value,\n",
    "                })\n",
    "            else:\n",
    "                get_tokens(i)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "get_tokens(where)\n",
    "for i in sql_tokens:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入 LIST 系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'employee_type', 'value': \"employee_type = 'Employee'\"}\n",
      "{'key': 'employment_status', 'value': \"employment_status = 'Active'\"}\n",
      "{'key': 'employment_status', 'value': \"employment_status = 'On Leave'\"}\n",
      "{'key': 'time_type', 'value': \"time_type='Full time'\"}\n",
      "{'key': 'country_code', 'value': \"country_code <> 'US'\"}\n",
      "{'key': 'hire_date', 'value': 'hire_date < NOW()'}\n",
      "{'key': 'LENGTH', 'value': 'LENGTH(email_work) > 0'}\n",
      "{'key': 'job_profile_id', 'value': \"(job_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE')\"}\n",
      "{'key': 'job_profile_id', 'value': 'where'}\n",
      "{'key': 'country_code', 'value': 'where'}\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "s = \"select count(*) from users where employee_type = 'Employee' AND (employment_status = 'Active' OR employment_status = 'On Leave') AND (time_type='Full time' OR country_code <> 'US') AND hire_date < NOW() AND email_work IS NOT NULL AND LENGTH(email_work) > 0 AND NOT (job_profile_id IN ('8802 - Comm Ops - 1', '8801 - CityOps - 2', '10034', '10455', '21014', '21015', '21016', '21018', '21017', '21019') AND country_code = 'IE') AND job_profile_id NOT IN ('20992', '20993', '20994', '20995', '20996', '20997') AND country_code NOT IN ('CN', 'MO', 'SG', 'MY', 'TH', 'VN', 'MM', 'KH', 'PH', 'ID')\"\n",
    "\n",
    "parsed = sqlparse.parse(s)\n",
    "where = parsed[0][-1]\n",
    "\n",
    "sql_tokens = []\n",
    "def get_tokens(where):\n",
    "    identifier = None\n",
    "    for i in where.tokens:\n",
    "        try:\n",
    "            name = i.get_real_name()\n",
    "            if name and isinstance(i, sqlparse.sql.Identifier):\n",
    "                identifier = i\n",
    "            elif identifier and isinstance(i, sqlparse.sql.Parenthesis):\n",
    "                sql_tokens.append({\n",
    "                    'key': str(identifier),\n",
    "                    'value': token.value\n",
    "                })\n",
    "            elif name:\n",
    "                identifier = None\n",
    "                # sql_tokens.append(\"{0} - {1} - {2}\".format(str(i), str(name), i.value))\n",
    "                sql_tokens.append({\n",
    "                    'key': str(name),\n",
    "                    'value': u''.join(token.value for token in i.flatten()),\n",
    "                })\n",
    "            else:\n",
    "                get_tokens(i)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "get_tokens(where)\n",
    "for i in sql_tokens:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Where 'where ...' at 0x21CCF736848>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxx']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "re.split(\"\\\\.\",\"xxx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
